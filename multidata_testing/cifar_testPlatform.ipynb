{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import seed\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import client_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "client_util.change_dir(\"avg_weights\",cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(x,y_actual,keep_prob):\n",
    "    #first conv layer\n",
    "    W1 = np.load(\"conv1_W1_avg.npy\",allow_pickle=True)\n",
    "    b1 = np.load(\"conv1_b1_avg.npy\",allow_pickle=True)\n",
    "    conv_1 = tf.nn.relu(tf.nn.conv2d(x, W1, [1, 1, 1, 1], padding='SAME') + b1)\n",
    "    pool_1 = tf.nn.max_pool(conv_1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool_1')\n",
    "    \n",
    "    #second conv layer\n",
    "    W2 = np.load(\"conv2_W2_avg.npy\",allow_pickle=True)\n",
    "    b2 = np.load(\"conv2_b2_avg.npy\",allow_pickle=True)\n",
    "    conv_2 = tf.nn.relu(tf.nn.conv2d(pool_1, W2, [1, 1, 1, 1], padding='SAME') + b2)\n",
    "    pool_2 = tf.nn.max_pool(conv_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool_2')\n",
    "\n",
    "    #flatten pool_2\n",
    "    dim2 = pool_2.get_shape()[1].value * pool_2.get_shape()[2].value * pool_2.get_shape()[3].value\n",
    "    pool_2_flat = tf.reshape(pool_2, [-1, dim2])\n",
    "    \n",
    "    #first fully connected layer\n",
    "    W_fc1 = np.load(\"fc1_W3_avg.npy\",allow_pickle=True)\n",
    "    b_fc1 = np.load(\"fc1_b3_avg.npy\",allow_pickle=True)\n",
    "    fc_1 = tf.nn.relu(tf.matmul(pool_2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    #add dropout layer\n",
    "    fc_1_drop = tf.nn.dropout(fc_1, keep_prob)\n",
    "    \n",
    "    #output layer\n",
    "    W_fc2 = np.load(\"w4_avg.npy\",allow_pickle=True)\n",
    "    b_fc2 = np.load(\"b4_avg.npy\",allow_pickle=True)\n",
    "    y_pred = tf.matmul(fc_1_drop, W_fc2) + b_fc2\n",
    "\n",
    "    print(\"===========test model loaded==============\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28), y_train shape: (60000,)\n",
      "x_train type: <class 'numpy.ndarray'>, y_train type: <class 'numpy.ndarray'>\n",
      "x_train shape: (60000, 28, 28), y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28), y_test shape: (10000,)\n",
      "x_train shape: (60000, 28, 28, 1), y_train shape: (60000, 10)\n",
      "x_train type: <class 'numpy.ndarray'>, y_train type: <class 'numpy.ndarray'>\n",
      "WARNING:tensorflow:From <ipython-input-3-191bc65ad73e>:24: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "===========test model loaded==============\n",
      "Epoch: 0, Testing accuracy: 0.09679999947547913\n",
      "Epoch: 2, Testing accuracy: 0.09749999642372131\n",
      "Epoch: 4, Testing accuracy: 0.09560000151395798\n",
      "Epoch: 6, Testing accuracy: 0.09080000221729279\n",
      "Epoch: 8, Testing accuracy: 0.10140000283718109\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    datasets = ['cifar10','mnist','fashion_mnist']\n",
    "    curr_testingData = datasets[0]\n",
    "    #load dataset\n",
    "    x_train,y_train,x_test,y_test = client_util.load_dataset(curr_testingData)\n",
    "    print(\"x_train shape: {}, y_train shape: {}\".format(x_train.shape,y_train.shape))\n",
    "    print(\"x_test shape: {}, y_test shape: {}\".format(x_test.shape,y_test.shape))\n",
    "    \n",
    "    #expand dimensions if mnist or fashion_mnist since cnn expect 4 dimension\n",
    "    if curr_testingData != \"cifar10\":\n",
    "        x_train = np.expand_dims(x_train,axis = -1)\n",
    "        x_test = np.expand_dims(x_test,axis = -1)\n",
    "        \n",
    "    #normalize data\n",
    "    x_train,y_train,x_test,y_test = client_util.normalize_data(x_train,y_train,x_test,y_test)\n",
    "    \n",
    "    #training parameters\n",
    "    if curr_testingData == \"cifar10\":\n",
    "        img_width = 32\n",
    "        img_height = 32\n",
    "        num_channels = 3\n",
    "    else:\n",
    "        img_width = 28\n",
    "        img_height = 28\n",
    "        num_channels = 1\n",
    "    num_classes = 10\n",
    "    \n",
    "    #create placeholders\n",
    "    x = tf.placeholder(tf.float32,shape=[None,img_width,img_height,num_channels])\n",
    "    y_actual = tf.placeholder(tf.float32,shape=[None,num_classes])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    #get prediction\n",
    "    y_pred = test_model(x,y_actual,keep_prob)\n",
    "    \n",
    "    with tf.variable_scope('acc',reuse = tf.AUTO_REUSE):\n",
    "        matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_actual,1))\n",
    "        acc = tf.reduce_mean(tf.cast(matches,tf.float32)) \n",
    "    \n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        test_acc_list = []\n",
    "    \n",
    "        for epoch in range(10):\n",
    "            #shuffle data \n",
    "\n",
    "            test_acc = acc.eval(feed_dict = {x:x_test, y_actual:y_test,keep_prob: 0.5})\n",
    "            test_acc_list.append(test_acc)\n",
    "\n",
    "            if epoch%2==0:\n",
    "                print(\"Epoch: {}, Testing accuracy: {}\".format(epoch,test_acc))\n",
    "            \n",
    "        cwd = os.getcwd()\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "federated_learning",
   "language": "python",
   "name": "federated_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
