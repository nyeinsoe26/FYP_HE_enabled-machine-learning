{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import seed\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training specifications\n",
    "batch_size = 1000\n",
    "NUM_CHANNELS = 3 #RGB image\n",
    "conv_fm1 = 50\n",
    "conv_fm2=60\n",
    "NUM_CLASSES=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_order_sampling(x_train,y_train,num_clients):\n",
    "    clients_data = []\n",
    "    clients = []\n",
    "    \n",
    "    partition_length = int((len(x_train))/num_clients)\n",
    "    \n",
    "    for i in range(num_clients):\n",
    "        clients_data.append(x_train[0:partition_length])\n",
    "        clients_data.append(y_train[0:partition_length])\n",
    "        clients.append(clients_data)\n",
    "        \n",
    "        x_train = x_train[partition_length:len(x_train)]\n",
    "        y_train = y_train[partition_length:len(y_train)]\n",
    "        \n",
    "        clients_data = []\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeatedSampling(x_train,y_train,num_clients):\n",
    " \n",
    "    partition_length = int((len(x_train))/num_clients)\n",
    "    x_train,y_train = shuffle(x_train,y_train)\n",
    "    clients_data = []\n",
    "    clients = []\n",
    "    \n",
    "    seed(1)\n",
    "    for i in range(num_clients):\n",
    "        temp_x = np.zeros((partition_length,32,32,3))\n",
    "        temp_y = np.zeros((partition_length,10))\n",
    "        for index in range(partition_length):\n",
    "            randnum = randint(0,len(x_train)-1)\n",
    "            temp_x[index] = x_train[randnum]\n",
    "            temp_y[index] = y_train[randnum]\n",
    "            \n",
    "        clients_data.append(temp_x)\n",
    "        clients_data.append(temp_y)\n",
    "        clients.append(clients_data)\n",
    "        \n",
    "        x_train,y_train = shuffle(x_train,y_train)\n",
    "        \n",
    "        clients_data = []\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_repeatedSampling(x_train,y_train,num_clients):\n",
    " \n",
    "    partition_length = int((len(x_train))/num_clients)\n",
    "    x_train,y_train = shuffle(x_train,y_train)\n",
    "    clients_data = []\n",
    "    clients = []\n",
    "    \n",
    "    seed(1)\n",
    "    for i in range(num_clients):\n",
    "        clients_data.append(x_train[0:partition_length])\n",
    "        clients_data.append(y_train[0:partition_length])\n",
    "        clients.append(clients_data)\n",
    "        \n",
    "        x_train = x_train[partition_length:len(x_train)]\n",
    "        y_train = y_train[partition_length:len(y_train)]\n",
    "        x_train,y_train = shuffle(x_train,y_train)\n",
    "        \n",
    "        clients_data = []\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#testing partition function\n",
    "clients = non_repeatedSampling(x_train,y_train,4)\n",
    "client1 = clients[0]\n",
    "print(len(client1))\n",
    "#print(\"x_train_1: {}, y_train_1: {}\".format(client1[0].shape,client1[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data):\n",
    "    if data==\"cifar10\":\n",
    "        (x_train,y_train),(x_test,y_test) = cifar10.load_data()\n",
    "    else:\n",
    "        (x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "    \n",
    "    print(\"x_train shape: {}, y_train shape: {}\".format(x_train.shape,y_train.shape))\n",
    "    print(\"x_train type: {}, y_train type: {}\".format(type(x_train),type(y_train)))\n",
    "    \n",
    "    return x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(x_train,y_train,x_test,y_test):\n",
    "    x_train = x_train.astype(\"float32\")\n",
    "    x_test = x_test.astype(\"float32\")\n",
    "    x_train = x_train/255\n",
    "    x_test = x_test/255\n",
    "    y_train = keras.utils.to_categorical(y_train,10)\n",
    "    y_test = keras.utils.to_categorical(y_test,10)\n",
    "    print(\"x_train shape: {}, y_train shape: {}\".format(x_train.shape,y_train.shape))\n",
    "    print(\"x_train type: {}, y_train type: {}\".format(type(x_train),type(y_train)))\n",
    "    return x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3), y_train shape: (50000, 1)\n",
      "x_train type: <class 'numpy.ndarray'>, y_train type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test = load_dataset(\"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3), y_train shape: (50000, 10)\n",
      "x_train type: <class 'numpy.ndarray'>, y_train type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test = normalize_data(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(x_train)\n",
    "idx = np.arange(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare placeholders\n",
    "x = tf.placeholder(tf.float32,shape=[None,32,32,3])\n",
    "y_actual = tf.placeholder(tf.float32,shape=[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1_shape: Tensor(\"Shape:0\", shape=(4,), dtype=int32), b1_shape: Tensor(\"Shape_1:0\", shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "W1 = np.load(\"conv_1_weights_1.npy\",allow_pickle=True)\n",
    "b1 = np.load(\"conv_1_biases_1.npy\",allow_pickle=True)\n",
    "conv_1 = tf.nn.relu(tf.nn.conv2d(x, W1, [1, 1, 1, 1], padding='VALID') + b1)\n",
    "pool_1 = tf.nn.max_pool(conv_1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool_1')\n",
    "print(\"W1_shape: {}, b1_shape: {}\".format(tf.shape(W1),tf.shape(b1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2_shape: Tensor(\"Shape_2:0\", shape=(4,), dtype=int32), b2_shape: Tensor(\"Shape_3:0\", shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "W2 = np.load(\"conv_2_weights_2.npy\",allow_pickle=True)\n",
    "b2 = np.load(\"conv_2_biases_2.npy\",allow_pickle=True)\n",
    "conv_2 = tf.nn.relu(tf.nn.conv2d(pool_1, W2, [1, 1, 1, 1], padding='SAME') + b2)\n",
    "pool_2 = tf.nn.max_pool(conv_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool_2')\n",
    "print(\"W2_shape: {}, b2_shape: {}\".format(tf.shape(W2),tf.shape(b2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten pool_2\n",
    "dim2 = pool_2.get_shape()[1].value * pool_2.get_shape()[2].value * pool_2.get_shape()[3].value\n",
    "pool_2_flat = tf.reshape(pool_2, [-1, dim2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_fc1_shape: Tensor(\"Shape_4:0\", shape=(2,), dtype=int32), b_fc1_shape: Tensor(\"Shape_5:0\", shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "W_fc1 = np.load(\"fc_1_weights_3.npy\",allow_pickle=True)\n",
    "b_fc1 = np.load(\"fc_1_biases_3.npy\",allow_pickle=True)\n",
    "fc_1 = tf.nn.relu(tf.matmul(pool_2_flat, W_fc1) + b_fc1)\n",
    "print(\"W_fc1_shape: {}, b_fc1_shape: {}\".format(tf.shape(W_fc1),tf.shape(b_fc1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-1fa34c616f3a>:2: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#add dropout layer\n",
    "fc_1_drop = tf.nn.dropout(fc_1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_fc2_shape: Tensor(\"Shape_6:0\", shape=(2,), dtype=int32), b_fc2_shape: Tensor(\"Shape_7:0\", shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "W_fc2 = np.load(\"weights_4.npy\",allow_pickle=True)\n",
    "b_fc2 = np.load(\"biases_4.npy\",allow_pickle=True)\n",
    "y_pred = tf.matmul(fc_1_drop, W_fc2) + b_fc2\n",
    "print(\"W_fc2_shape: {}, b_fc2_shape: {}\".format(tf.shape(W_fc2),tf.shape(b_fc2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('acc',reuse = tf.AUTO_REUSE):\n",
    "    matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_actual,1))\n",
    "    acc = tf.reduce_mean(tf.cast(matches,tf.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Testing accuracy: 0.6240000128746033\n",
      "Epoch: 2, Testing accuracy: 0.6510000228881836\n",
      "Epoch: 4, Testing accuracy: 0.6460000276565552\n",
      "Epoch: 6, Testing accuracy: 0.6690000295639038\n",
      "Epoch: 8, Testing accuracy: 0.6119999885559082\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    test_acc_list = []\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        #shuffle data \n",
    "        np.random.shuffle(idx)\n",
    "        x_train, y_train = x_train[idx],y_train[idx]\n",
    "        for start,end in zip(range(0,N,batch_size),range(batch_size,N,batch_size)):\n",
    "            if epoch==10:\n",
    "                print(\"Dummy training\")\n",
    "        test_acc = acc.eval(feed_dict = {x:x_train[start:end], y_actual:y_train[start:end],keep_prob: 0.5})\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "        if epoch%2==0:\n",
    "            print(\"Epoch: {}, Testing accuracy: {}\".format(epoch,test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "federated_learning",
   "language": "python",
   "name": "federated_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
